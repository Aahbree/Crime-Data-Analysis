{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Big_data_Capstone_remastered.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVb5lUga6HAG",
        "outputId": "d8192a56-02eb-4a07-f566-ee1d5ec42994"
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install openclean"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.0)\n",
            "Requirement already satisfied: py4j==0.10.9.2 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.2)\n",
            "Requirement already satisfied: openclean in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: openclean-core==0.4.1 in /usr/local/lib/python3.7/dist-packages (from openclean) (0.4.1)\n",
            "Requirement already satisfied: histore>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from openclean-core==0.4.1->openclean) (0.4.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from openclean-core==0.4.1->openclean) (2.8.2)\n",
            "Requirement already satisfied: jsonschema>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from openclean-core==0.4.1->openclean) (4.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from openclean-core==0.4.1->openclean) (1.4.1)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.7/dist-packages (from openclean-core==0.4.1->openclean) (1.4.4)\n",
            "Requirement already satisfied: flowserv-core>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from openclean-core==0.4.1->openclean) (0.9.2)\n",
            "Requirement already satisfied: refdata>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from openclean-core==0.4.1->openclean) (0.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from openclean-core==0.4.1->openclean) (2.23.0)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from openclean-core==0.4.1->openclean) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from openclean-core==0.4.1->openclean) (1.0.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from openclean-core==0.4.1->openclean) (0.16.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from openclean-core==0.4.1->openclean) (0.3.4)\n",
            "Requirement already satisfied: jellyfish in /usr/local/lib/python3.7/dist-packages (from openclean-core==0.4.1->openclean) (0.8.9)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.7/dist-packages (from flowserv-core>=0.8.0->openclean-core==0.4.1->openclean) (7.1.2)\n",
            "Requirement already satisfied: paramiko in /usr/local/lib/python3.7/dist-packages (from flowserv-core>=0.8.0->openclean-core==0.4.1->openclean) (2.8.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from flowserv-core>=0.8.0->openclean-core==0.4.1->openclean) (5.4.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.3.18 in /usr/local/lib/python3.7/dist-packages (from flowserv-core>=0.8.0->openclean-core==0.4.1->openclean) (1.4.27)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.7/dist-packages (from flowserv-core>=0.8.0->openclean-core==0.4.1->openclean) (3.1.24)\n",
            "Requirement already satisfied: passlib in /usr/local/lib/python3.7/dist-packages (from flowserv-core>=0.8.0->openclean-core==0.4.1->openclean) (1.7.4)\n",
            "Requirement already satisfied: pyyaml-include in /usr/local/lib/python3.7/dist-packages (from flowserv-core>=0.8.0->openclean-core==0.4.1->openclean) (1.2.post2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from histore>=0.4.0->openclean-core==0.4.1->openclean) (5.4.8)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->openclean-core==0.4.1->openclean) (21.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->openclean-core==0.4.1->openclean) (0.18.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->openclean-core==0.4.1->openclean) (4.8.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->openclean-core==0.4.1->openclean) (5.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.2.0->openclean-core==0.4.1->openclean) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.0->openclean-core==0.4.1->openclean) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.0->openclean-core==0.4.1->openclean) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->openclean-core==0.4.1->openclean) (1.15.0)\n",
            "Requirement already satisfied: pooch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from refdata>=0.2.0->openclean-core==0.4.1->openclean) (1.5.2)\n",
            "Requirement already satisfied: tableprint in /usr/local/lib/python3.7/dist-packages (from refdata>=0.2.0->openclean-core==0.4.1->openclean) (0.9.1)\n",
            "Requirement already satisfied: datasize>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from refdata>=0.2.0->openclean-core==0.4.1->openclean) (1.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pooch>=1.3.0->refdata>=0.2.0->openclean-core==0.4.1->openclean) (21.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.3.18->flowserv-core>=0.8.0->openclean-core==0.4.1->openclean) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython->flowserv-core>=0.8.0->openclean-core==0.4.1->openclean) (3.10.0.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython->flowserv-core>=0.8.0->openclean-core==0.4.1->openclean) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython->flowserv-core>=0.8.0->openclean-core==0.4.1->openclean) (5.0.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pooch>=1.3.0->refdata>=0.2.0->openclean-core==0.4.1->openclean) (3.0.6)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.7/dist-packages (from paramiko->flowserv-core>=0.8.0->openclean-core==0.4.1->openclean) (36.0.0)\n",
            "Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from paramiko->flowserv-core>=0.8.0->openclean-core==0.4.1->openclean) (1.4.0)\n",
            "Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from paramiko->flowserv-core>=0.8.0->openclean-core==0.4.1->openclean) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko->flowserv-core>=0.8.0->openclean-core==0.4.1->openclean) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko->flowserv-core>=0.8.0->openclean-core==0.4.1->openclean) (2.21)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->openclean-core==0.4.1->openclean) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->openclean-core==0.4.1->openclean) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->openclean-core==0.4.1->openclean) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->openclean-core==0.4.1->openclean) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->openclean-core==0.4.1->openclean) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->openclean-core==0.4.1->openclean) (3.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from tableprint->refdata>=0.2.0->openclean-core==0.4.1->openclean) (0.2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBCQs5QL6I6B"
      },
      "source": [
        "\n",
        "#importing packages required\n",
        "from pyspark import SparkContext, SparkConf\n",
        "import os\n",
        "import requests\n",
        "from six.moves import urllib\n",
        "import sys \n",
        "import pandas as pd\n",
        "import matplotlib \n",
        "import matplotlib as plt\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import IPython\n",
        "from IPython import display\n",
        "import sklearn\n",
        "import random\n",
        "import time\n",
        "import warnings\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from openclean.pipeline import stream\n",
        "from openclean.profiling.column import DefaultColumnProfiler\n",
        "from openclean.data.source.socrata import Socrata\n",
        "from openclean.pipeline import stream\n",
        "from openclean.function.eval.datatype import IsDatetime\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession, Row\n",
        "from pyspark.sql.functions import udf, struct\n",
        "from pyspark.sql.types import StringType"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from geopy.geocoders import ArcGIS\n",
        "geocoder=ArcGIS()\n",
        "#example:\n",
        "geocoder.reverse('40.61157006600007, -73.74736517199995')"
      ],
      "metadata": {
        "id": "iNbQ2NS_hXCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0574578-4f01-40c2-eab4-b02ec4774895"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Location(11-64 Redfern Ave, Far Rockaway, New York 11691, USA, (40.61161616586613, -73.74738361194636, 0.0))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNMWmGDp6o4X"
      },
      "source": [
        "#Creating Spark Session\n",
        "sc = SparkContext.getOrCreate();\n",
        "spark = SparkSession(sc)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzHz2Npm6PkX",
        "outputId": "8660e544-1bf6-47b1-f244-4173db9d0f9a"
      },
      "source": [
        "#Downloading file from NYC Open Data\n",
        "fn_src = 'https://data.cityofnewyork.us/api/views/qgea-i56i/rows.csv?accessType=DOWNLOAD'\n",
        "fn_dst = '/content/drive/MyDrive/NYPD_Complaint_Data_Historic.csv'\n",
        "\n",
        "#https://data.cityofnewyork.us/resource/h9gi-nx95.csv\n",
        "\n",
        "from six.moves import urllib\n",
        "\n",
        "if os.path.isfile(fn_dst):\n",
        "    print('File %s has already been downloaded' % fn_dst)\n",
        "else:\n",
        "    print('Fetching file %s[2.4GB]. This may take a while...' % fn_dst)\n",
        "    urllib.request.urlretrieve(fn_src, fn_dst)\n",
        "    print('File %s has been downloaded' % fn_dst)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File /content/drive/MyDrive/NYPD_Complaint_Data_Historic.csv has already been downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRngVDqU68D0"
      },
      "source": [
        "#Using openclean for finding anomalies\n",
        "ds = stream(fn_dst)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lets Profile the data first and check for number of null values present in each columns. \n",
        "CMPLNT_NUM, RPT_DT, KY_CD, LAW_CAT_CD have no null values\n",
        "\n",
        "Also, based on the qualitative analysis, lets include our area of interest (columns to consider)."
      ],
      "metadata": {
        "id": "YMwWS6CM4v0G"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecFP8c6l7EiP"
      },
      "source": [
        "#Creating profile of our dataset\n",
        "profiles = ds.profile(default_profiler=DefaultColumnProfiler)\n",
        "profiles.stats()"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets check the all the data types and their unique values' count for each column.\n",
        "\n",
        "print('Schema\\n------')\n",
        "for col in ds.columns:\n",
        "    p = profiles.column(col)\n",
        "    print(\"  '{}' ({})\".format(col, p['datatypes']['distinct'].most_common(2)))"
      ],
      "metadata": {
        "id": "kw_T9BTAfRct"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets load the data to spark\n",
        "df_spark=spark.read.option(\"header\",True).csv(fn_dst,inferSchema=True) # data set 1."
      ],
      "metadata": {
        "id": "ueuZwSCCz9YD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pCw9TwoG6Kk"
      },
      "source": [
        "# 1. We can consider the following columns as our area of interest:\n",
        "\n",
        "1. CMPLNT_NUM\t\n",
        "Randomly generated persistent ID for each complaint\n",
        "2. CMPLNT_FR_DT\t\n",
        "Exact date of occurrence for the reported event \n",
        "3. CMPLNT_FR_TM\t\n",
        "Exact time of occurrence for the reported event\n",
        "4. ADDR_PCT_CD\t\n",
        "The precinct in which the incident occurred\n",
        "5. KY_CD\t\n",
        "Three digit offense classification code\n",
        "6. LAW_CAT_CD\t\n",
        "Level of offense: felony, misdemeanor, violation\n",
        "7. BORO_NM\t\n",
        "The name of the borough in which the incident occurred\n",
        "8. PREM_TYP_DESC\t\n",
        "Specific description of premises; grocery store, residence, street, etc.\n",
        "9. VIC_AGE_GROUP\t\n",
        "Victim’s Age Group\n",
        "10. VIC_RACE\t\n",
        "Victim’s Race Description\n",
        "11. VIC_SEX\t\n",
        "Victim’s Sex Description\n",
        "12. Latitude\n",
        "13. Longitude\n",
        "14. SUSP_AGE_GROUP\t\n",
        "Suspect’s Age Group\n",
        "15. SUSP_RACE\t\n",
        "Suspect’s Race Description\n",
        "16. SUSP_SEX\t\n",
        "Suspect’s Sex Description\n",
        "17. JURISDICTION_CODE\n",
        "18. PATROL_BORO\n",
        "19. PD_CD\n",
        "20. HOUSING_PSA\t\n",
        "Development Level Code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#similarly, lets get them into pyspark rdd\n",
        "def get_area_of_interest(df_spark, interested_columns):\n",
        "  df_spark=df_spark.select(interested_columns)\n",
        "  return df_spark"
      ],
      "metadata": {
        "id": "ZYeKXnuFuiZn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interested_columns=['CMPLNT_NUM','CMPLNT_FR_DT','CMPLNT_FR_TM', 'ADDR_PCT_CD', 'KY_CD', 'LAW_CAT_CD', 'LAW_CAT_CD', 'BORO_NM', 'PREM_TYP_DESC', 'VIC_AGE_GROUP', \n",
        "           'VIC_RACE', 'VIC_SEX', 'Latitude', 'Longitude', 'SUSP_AGE_GROUP', 'SUSP_RACE', 'SUSP_SEX', 'JURISDICTION_CODE', 'PATROL_BORO', 'PD_CD','HOUSING_PSA']\n"
      ],
      "metadata": {
        "id": "6Q8pBpVKV3k-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark=get_area_of_interest(df_spark, interested_columns)"
      ],
      "metadata": {
        "id": "d5qNxoV41QOj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp=df_spark.rdd\n",
        "# temp=df_temp.toDF(schema=df_spark.columns)"
      ],
      "metadata": {
        "id": "bUPMif3Q7427"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Lets work with the dates first"
      ],
      "metadata": {
        "id": "paTgNQZp2JK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the dataset is for the data from 2006 to 2020, we can see that there is data from unknown format of \"1010-05-14\" to the year 2020. We need to clean this. Over here, we remove the null values where the complaint date is <2006. "
      ],
      "metadata": {
        "id": "ywjL6qSd61cH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fileName='1010-05-14 00:00:00'\n",
        "# # matches=re.search(\"([0-9]{4}\\-[0-9]{2}\\-[0-9]{2})\", fileName)\n",
        "# re.search(r'([0-9]{4}\\-[0-9]{2}\\-[0-9]{2})', fileName).group(0)\n",
        "\n",
        "def valid_date_check(date):\n",
        "  if date==None or date==\" \" or date==\"\":\n",
        "      return False\n",
        "  else:\n",
        "    date_cpy=date\n",
        "    date=date.split(\"/\")\n",
        "    try:\n",
        "      month=int(date[0])\n",
        "      day= int(date[1])\n",
        "      year=int(date[2])\n",
        "      if year>=2006 and year<=2020:\n",
        "        try:\n",
        "          refined_date=datetime.datetime(year, month, day)\n",
        "          return True\n",
        "        except:\n",
        "          return False\n",
        "      else:\n",
        "        return False\n",
        "    except:\n",
        "      return False"
      ],
      "metadata": {
        "id": "wLnEE_HC2tsJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filter the dates with proper format for Column-2 (CMPLNT_FR_DT)\n",
        "df_temp_=df_temp.map(lambda x:(x, valid_date_check(x[1]))).filter(lambda x: x[1]==True)\n",
        "df_temp=df_temp_.map(lambda x: x[0])"
      ],
      "metadata": {
        "id": "0N0E0YPw8pAK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Lets work on time related columns\n",
        "\n",
        "Similarly, lets check for the time as well. Here we must have time between \n",
        "the standard 24 hours.\n"
      ],
      "metadata": {
        "id": "AafXi_lG6AHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Deleting invalid time\n",
        "def valid_time_check(time):\n",
        "  if time==None or time==\" \" or time==\"\":\n",
        "    return False\n",
        "  else :\n",
        "    cpy_time=time\n",
        "    time=time.split(\":\")\n",
        "    try:\n",
        "      hour=int(time[0])\n",
        "      mins=int(time[1])\n",
        "      secs= int(time[2])\n",
        "      # if hours is 24 then change it to 0 hours\n",
        "      if hour == 24 and mins== 0 and secs == 0:\n",
        "        hour=0\n",
        "      try:\n",
        "        newTime= datetime.time(hour,mins,secs)\n",
        "        return True\n",
        "      except :\n",
        "        return False\n",
        "    except:\n",
        "      return False"
      ],
      "metadata": {
        "id": "_9DbXvl2-qXx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp_=df_temp.map(lambda x:(x, valid_time_check(x[2]))).filter(lambda x: x[1]==True)\n",
        "df_temp=df_temp_.map(lambda x: x[0])"
      ],
      "metadata": {
        "id": "GB2IsTcyCCrl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp.take(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23NT8eFICLL7",
        "outputId": "9aa7e850-a56c-457d-bbe9-6cf82e0ed4b1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(CMPLNT_NUM=394506329, CMPLNT_FR_DT='12/31/2019', CMPLNT_FR_TM='17:30:00', ADDR_PCT_CD=32, KY_CD=118, LAW_CAT_CD='FELONY', LAW_CAT_CD='FELONY', BORO_NM='MANHATTAN', PREM_TYP_DESC='STREET', VIC_AGE_GROUP='UNKNOWN', VIC_RACE='UNKNOWN', VIC_SEX='E', Latitude=40.82092679700002, Longitude=-73.94332421899996, SUSP_AGE_GROUP=None, SUSP_RACE=None, SUSP_SEX=None, JURISDICTION_CODE=0, PATROL_BORO='PATROL BORO MAN NORTH', PD_CD=793, HOUSING_PSA=None),\n",
              " Row(CMPLNT_NUM=968873685, CMPLNT_FR_DT='12/29/2019', CMPLNT_FR_TM='16:31:00', ADDR_PCT_CD=47, KY_CD=113, LAW_CAT_CD='FELONY', LAW_CAT_CD='FELONY', BORO_NM='BRONX', PREM_TYP_DESC='STREET', VIC_AGE_GROUP='UNKNOWN', VIC_RACE='UNKNOWN', VIC_SEX='E', Latitude=40.885701406000074, Longitude=-73.86164032499995, SUSP_AGE_GROUP=None, SUSP_RACE=None, SUSP_SEX=None, JURISDICTION_CODE=0, PATROL_BORO='PATROL BORO BRONX', PD_CD=729, HOUSING_PSA=None)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Lets refine the Age Group and Race columns\n",
        "The module works for only those columns whose column names are passed"
      ],
      "metadata": {
        "id": "EOs4OL0X5T82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def refine_age_group_race(df_spark, victim_age_group=None, suspect_age_group=None, suspect_race=None, victim_race=None):\n",
        "  #params: dataframe, col names for the respective age, gender cols\n",
        "  if victim_age_group:\n",
        "    df_spark = df_spark.na.fill(\"UNKNOWN\",subset=[victim_age_group])\n",
        "  if suspect_age_group:\n",
        "    df_spark = df_spark.na.fill(\"UNKNOWN\",subset=[suspect_age_group])\n",
        "  if suspect_race:\n",
        "    df_spark = df_spark.na.fill(\"UNKNOWN\",subset=[suspect_race])\n",
        "  if victim_race:\n",
        "    df_spark = df_spark.na.fill(\"UNKNOWN\",subset=[victim_race])\n",
        "  return df_spark"
      ],
      "metadata": {
        "id": "KALVlifX61a0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp=refine_age_group_race(df_spark, \"VIC_AGE_GROUP\", \"SUSP_AGE_GROUP\", 'SUSP_RACE', 'VIC_RACE')"
      ],
      "metadata": {
        "id": "2n2_DVcnqUhn"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Lets refine the Gender, Race Columns for suspects and victims\n",
        "\n",
        "The module works for only those columns whose column names are passed"
      ],
      "metadata": {
        "id": "LQQ2i6zk5Tz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def refine_sex_gender_impute(df_spark, suspect_age=None, suspect_gender=None, victim_age=None, victim_gender=None):\n",
        "  #params: dataframe, col names for the respective age, gender cols\n",
        "  if suspect_age:\n",
        "    df_spark=df_spark.na.fill(\"U\",subset=[suspect_age])\n",
        "  if victim_age:\n",
        "    df_spark=df_spark.na.fill(\"U\",subset=[victim_age])\n",
        "  if suspect_gender:\n",
        "    df_spark = df_spark.na.fill(\"UNKNOWN\",subset=[suspect_gender])\n",
        "  if victim_gender:\n",
        "    df_spark = df_spark.na.fill(\"UNKNOWN\",subset=[victim_gender])\n",
        "  return df_spark"
      ],
      "metadata": {
        "id": "FBN0cQbt63x8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp=refine_sex_gender_impute(df_temp, None, 'SUSP_SEX', None, 'VIC_SEX')"
      ],
      "metadata": {
        "id": "6-aFZnR4qfgP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Geospacial Attributes Imputation: "
      ],
      "metadata": {
        "id": "8Z0v3wIQp7NE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.a: Precinct, Jurisdiction Code:\n",
        "  dropping the null values\n",
        "\n",
        "  The module works for only those columns whose column names are passed along with the df"
      ],
      "metadata": {
        "id": "ndsrr-zGqDfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def valid_precinct_check(precinct):\n",
        "  if precinct==None or precinct==\" \" or precinct==\"\":\n",
        "    return False\n",
        "  else :\n",
        "    return True\n",
        "\n",
        "def valid_jur_check(jur):\n",
        "  if jur==None or jur==\" \" or jur==\"\":\n",
        "    return False\n",
        "  else :\n",
        "    return True"
      ],
      "metadata": {
        "id": "Nv_u_xjWojid"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp=df_temp.rdd\n",
        "\n",
        "df_temp_=df_temp.map(lambda x:(x, valid_precinct_check(x[3]))).filter(lambda x: x[1]==True)\n",
        "df_temp=df_temp_.map(lambda x: x[0])\n",
        "\n",
        "df_temp_=df_temp.map(lambda x:(x, valid_jur_check(x[-4]))).filter(lambda x: x[1]==True)\n",
        "df_temp=df_temp_.map(lambda x: x[0])"
      ],
      "metadata": {
        "id": "HNejyXlvsPkw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp=df_temp.toDF(schema=df_spark.schema)"
      ],
      "metadata": {
        "id": "_euh-k5EDcOI"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.b Reverse Geocoding the boroughs using latitudes and longitudes.\n",
        "\n",
        "1. First we will remove the rows where latitude, longitude and boroughs are null. (around 450 tuples removed)\n",
        "2. Then, where the boroughs are empty, take the latitude and longitude value and reverse geocode it using the module \"reverseGeocoder\".\n",
        "3. Impute the borough name retrived in the empty space."
      ],
      "metadata": {
        "id": "WjgCv26iwhwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, lets remove the rows where latitudes and longitudes are NULL. After that, we can take only those rows where BORO_NM is Null. So, we have 5000 points of BORO_NM to impute using latitudes and longitudes. These are the rows where BORO_NM is null"
      ],
      "metadata": {
        "id": "8FcNjpph4hft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp_boro_clean=df_temp.filter((df_temp.Latitude.isNotNull()) & (df_temp.Longitude.isNotNull()))"
      ],
      "metadata": {
        "id": "bDF18fmG3HUN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boro_cleaner=df_temp_boro_clean.filter(df_temp_boro_clean.BORO_NM.isNull())"
      ],
      "metadata": {
        "id": "TGHjp1stbYZW"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boro_cleaner.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU5POtzGrXhk",
        "outputId": "7b97ad2c-7bea-43f9-c957-5a2622fb3cf9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5049"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### USING MASTER DATASET\n",
        "In the case of geocoding, geocoder gives us the zipcodes based on the latitude and longitude values. Inturn, we can use the master dataset of zipcodes inorder to retrive the borough names\n",
        "\n",
        "\n",
        "\n",
        "NOTE: The dataset can be downloaded from : https://data.beta.nyc/en/dataset/pediacities-nyc-neighborhoods/resource/7caac650-d082-4aea-9f9b-3681d568e8a5"
      ],
      "metadata": {
        "id": "iiz-d-TNz3pE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#use your path for master dataset here. \n",
        "df_zips=pd.read_csv(\"/content/drive/MyDrive/nyc_zip_borough_neighborhoods_pop.csv\")\n",
        "zip_master={}\n",
        "zips=df_zips['zip']\n",
        "boro=df_zips['borough']\n",
        "for i, j in zip(zips, boro):\n",
        "  zip_master[i]=j"
      ],
      "metadata": {
        "id": "7abubwRXvlY2"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_master[10020]='Manhattan'\n",
        "zip_master[11249]='Brooklyn'"
      ],
      "metadata": {
        "id": "vTYGOoaLCcKO"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We stored the zip codes and their corresponding borough names in the dictionary \"zip_master\" in the form of a look-up because, it takes O(1) time to retrive borough names hence reduces parse time."
      ],
      "metadata": {
        "id": "kfOM7IVKzziB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reverseGeoCoder(latitude, longitude):\n",
        "  loc=geocoder.reverse(str(latitude)+', '+str(longitude))\n",
        "  zipCode=str(loc).split(\",\")[2][-5:]\n",
        "  if not int(zipCode) in zip_master:\n",
        "    boro=\"UNKNOWN\"\n",
        "  else:\n",
        "    boro=zip_master[int(zipCode)]\n",
        "  boro=boro.upper()\n",
        "  return boro"
      ],
      "metadata": {
        "id": "JHZawp2Qghvt"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ud_func= udf(reverseGeoCoder, StringType())\n",
        "boro_cleaned_dataframe = boro_cleaner.withColumn(\"BORO_NM\", ud_func(boro_cleaner[12], boro_cleaner[13]))"
      ],
      "metadata": {
        "id": "TgbcKoAwsqvT"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boro_cleaned_dataframe.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZBDQ-IVtZzb",
        "outputId": "9625ebab-7bcb-4a42-f332-64178c79432b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(CMPLNT_NUM=375517764, CMPLNT_FR_DT='12/22/2019', CMPLNT_FR_TM='14:32:00', ADDR_PCT_CD=25, KY_CD=343, LAW_CAT_CD='MISDEMEANOR', LAW_CAT_CD='MISDEMEANOR', BORO_NM='MANHATTAN', PREM_TYP_DESC='TRANSIT - NYC SUBWAY', VIC_AGE_GROUP='UNKNOWN', VIC_RACE='UNKNOWN', VIC_SEX='E', Latitude=40.80093037300003, Longitude=-73.94109824099996, SUSP_AGE_GROUP='25-44', SUSP_RACE='BLACK', SUSP_SEX='M', JURISDICTION_CODE=1, PATROL_BORO='PATROL BORO MAN NORTH', PD_CD=475, HOUSING_PSA=None),\n",
              " Row(CMPLNT_NUM=598430372, CMPLNT_FR_DT='12/20/2019', CMPLNT_FR_TM='19:50:00', ADDR_PCT_CD=6, KY_CD=106, LAW_CAT_CD='FELONY', LAW_CAT_CD='FELONY', BORO_NM='MANHATTAN', PREM_TYP_DESC='TRANSIT - NYC SUBWAY', VIC_AGE_GROUP='UNKNOWN', VIC_RACE='UNKNOWN', VIC_SEX='E', Latitude=40.73389675800007, Longitude=-74.005395837, SUSP_AGE_GROUP='UNKNOWN', SUSP_RACE='UNKNOWN', SUSP_SEX='UNKNOWN', JURISDICTION_CODE=1, PATROL_BORO='PATROL BORO MAN SOUTH', PD_CD=106, HOUSING_PSA=None),\n",
              " Row(CMPLNT_NUM=775366730, CMPLNT_FR_DT='12/02/2019', CMPLNT_FR_TM='08:25:00', ADDR_PCT_CD=61, KY_CD=578, LAW_CAT_CD='VIOLATION', LAW_CAT_CD='VIOLATION', BORO_NM='BROOKLYN', PREM_TYP_DESC='TRANSIT - NYC SUBWAY', VIC_AGE_GROUP='25-44', VIC_RACE='ASIAN / PACIFIC ISLANDER', VIC_SEX='F', Latitude=40.59503787700004, Longitude=-73.95473598599993, SUSP_AGE_GROUP='45-64', SUSP_RACE='BLACK', SUSP_SEX='F', JURISDICTION_CODE=1, PATROL_BORO='PATROL BORO BKLYN SOUTH', PD_CD=637, HOUSING_PSA=None),\n",
              " Row(CMPLNT_NUM=246745254, CMPLNT_FR_DT='12/05/2019', CMPLNT_FR_TM='12:50:00', ADDR_PCT_CD=111, KY_CD=344, LAW_CAT_CD='MISDEMEANOR', LAW_CAT_CD='MISDEMEANOR', BORO_NM='QUEENS', PREM_TYP_DESC='PARK/PLAYGROUND', VIC_AGE_GROUP='45-64', VIC_RACE='WHITE', VIC_SEX='M', Latitude=40.76039613900008, Longitude=-73.76750253499995, SUSP_AGE_GROUP='UNKNOWN', SUSP_RACE='BLACK', SUSP_SEX='M', JURISDICTION_CODE=0, PATROL_BORO='PATROL BORO QUEENS NORTH', PD_CD=101, HOUSING_PSA=None),\n",
              " Row(CMPLNT_NUM=631691048, CMPLNT_FR_DT='08/30/2019', CMPLNT_FR_TM='07:30:00', ADDR_PCT_CD=19, KY_CD=109, LAW_CAT_CD='FELONY', LAW_CAT_CD='FELONY', BORO_NM='MANHATTAN', PREM_TYP_DESC='TRANSIT - NYC SUBWAY', VIC_AGE_GROUP='25-44', VIC_RACE='WHITE HISPANIC', VIC_SEX='M', Latitude=40.76699564200004, Longitude=-73.96392230399994, SUSP_AGE_GROUP='UNKNOWN', SUSP_RACE='UNKNOWN', SUSP_SEX='UNKNOWN', JURISDICTION_CODE=1, PATROL_BORO='PATROL BORO MAN NORTH', PD_CD=408, HOUSING_PSA=None),\n",
              " Row(CMPLNT_NUM=521427232, CMPLNT_FR_DT='08/22/2019', CMPLNT_FR_TM='13:35:00', ADDR_PCT_CD=1, KY_CD=113, LAW_CAT_CD='FELONY', LAW_CAT_CD='FELONY', BORO_NM='MANHATTAN', PREM_TYP_DESC='TRANSIT - NYC SUBWAY', VIC_AGE_GROUP='UNKNOWN', VIC_RACE='UNKNOWN', VIC_SEX='E', Latitude=40.72044188800004, Longitude=-74.00674397399997, SUSP_AGE_GROUP='45-64', SUSP_RACE='ASIAN / PACIFIC ISLANDER', SUSP_SEX='F', JURISDICTION_CODE=1, PATROL_BORO='PATROL BORO MAN SOUTH', PD_CD=729, HOUSING_PSA=None),\n",
              " Row(CMPLNT_NUM=161796516, CMPLNT_FR_DT='02/28/2019', CMPLNT_FR_TM='02:55:00', ADDR_PCT_CD=75, KY_CD=109, LAW_CAT_CD='FELONY', LAW_CAT_CD='FELONY', BORO_NM='BROOKLYN', PREM_TYP_DESC='TRANSIT - NYC SUBWAY', VIC_AGE_GROUP='25-44', VIC_RACE='BLACK', VIC_SEX='F', Latitude=40.67135982000008, Longitude=-73.88181102299995, SUSP_AGE_GROUP='UNKNOWN', SUSP_RACE='UNKNOWN', SUSP_SEX='M', JURISDICTION_CODE=1, PATROL_BORO='PATROL BORO BKLYN NORTH', PD_CD=408, HOUSING_PSA=None),\n",
              " Row(CMPLNT_NUM=772920292, CMPLNT_FR_DT='11/13/2008', CMPLNT_FR_TM='09:00:00', ADDR_PCT_CD=47, KY_CD=578, LAW_CAT_CD='VIOLATION', LAW_CAT_CD='VIOLATION', BORO_NM='BRONX', PREM_TYP_DESC='STREET', VIC_AGE_GROUP='25-44', VIC_RACE='UNKNOWN', VIC_SEX='M', Latitude=40.897092464, Longitude=-73.857623279, SUSP_AGE_GROUP='UNKNOWN', SUSP_RACE='UNKNOWN', SUSP_SEX='UNKNOWN', JURISDICTION_CODE=0, PATROL_BORO='PATROL BORO BRONX', PD_CD=638, HOUSING_PSA='NA'),\n",
              " Row(CMPLNT_NUM=578840360, CMPLNT_FR_DT='05/28/2010', CMPLNT_FR_TM='12:40:00', ADDR_PCT_CD=44, KY_CD=235, LAW_CAT_CD='MISDEMEANOR', LAW_CAT_CD='MISDEMEANOR', BORO_NM='BRONX', PREM_TYP_DESC='STREET', VIC_AGE_GROUP='UNKNOWN', VIC_RACE='UNKNOWN', VIC_SEX='E', Latitude=40.829663962, Longitude=-73.917285253, SUSP_AGE_GROUP='UNKNOWN', SUSP_RACE='UNKNOWN', SUSP_SEX='UNKNOWN', JURISDICTION_CODE=0, PATROL_BORO='PATROL BORO BRONX', PD_CD=567, HOUSING_PSA='NA'),\n",
              " Row(CMPLNT_NUM=493485412, CMPLNT_FR_DT='05/28/2010', CMPLNT_FR_TM='01:00:00', ADDR_PCT_CD=5, KY_CD=341, LAW_CAT_CD='MISDEMEANOR', LAW_CAT_CD='MISDEMEANOR', BORO_NM='MANHATTAN', PREM_TYP_DESC='STREET', VIC_AGE_GROUP='25-44', VIC_RACE='WHITE', VIC_SEX='M', Latitude=40.713453915, Longitude=-73.998536931, SUSP_AGE_GROUP='UNKNOWN', SUSP_RACE='UNKNOWN', SUSP_SEX='UNKNOWN', JURISDICTION_CODE=0, PATROL_BORO='PATROL BORO MAN SOUTH', PD_CD=335, HOUSING_PSA='NA')]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, we had the dataframe (boro_cleaner) where there were null values in BORO_NM column derived from the main dataframe (df_temp_boro_clean). Now we merge back the imputed dataframe back to the main dataframe."
      ],
      "metadata": {
        "id": "hoYsW9cl4GCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joiner_dataset=df_temp.filter((df_temp.Latitude.isNotNull()) & (df_temp.Longitude.isNotNull()) & (df_temp.BORO_NM.isNotNull()))\n",
        "fin_df=joiner_dataset.union(boro_cleaned_dataframe)"
      ],
      "metadata": {
        "id": "bhMLkABE01OI"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NOTE: Below modules for reverse geocoding is used for future purpose (Reverse Geocoding)"
      ],
      "metadata": {
        "id": "7NqMK0XF7jZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reverseGeoCoder(latitude, longitude):\n",
        "  loc=geocoder.reverse(str(latitude)+', '+str(longitude))\n",
        "  zipCode=str(loc).split(\",\")[2][-5:]\n",
        "  if not int(zipCode) in zip_master:\n",
        "    boro=\"UNKNOWN\"\n",
        "  else:\n",
        "    boro=zip_master[int(zipCode)]\n",
        "  boro=boro.upper()\n",
        "  return boro\n",
        "\n",
        "def reverse_geo_code_boros(df_spark, Latitude, Longitude, Boro, lat_index, long_index):\n",
        "  #select data where we have to impute\n",
        "  df_temp_boro_clean=df_spark.filter((df_spark[Latitude].isNotNull()) & (df_spark[Longitude].isNotNull()))\n",
        "  boro_cleaner=df_temp_boro_clean.filter(df_temp_boro_clean[Boro].isNull())\n",
        "  print(\"We have \"+ str(boro_cleaner.count())+ \" points to impute\")\n",
        "  print(\"___intializing Zip Code Look up ____\")\n",
        "  \n",
        "  #use your path for master dataset here. \n",
        "  df_zips=pd.read_csv(\"/content/drive/MyDrive/nyc_zip_borough_neighborhoods_pop.csv\")\n",
        "  zip_master={}\n",
        "  zips=df_zips['zip']\n",
        "  boro=df_zips['borough']\n",
        "  for i, j in zip(zips, boro):\n",
        "    zip_master[i]=j\n",
        "  zip_master[10020]='Manhattan'\n",
        "  zip_master[11249]='Brooklyn'\n",
        "\n",
        "  print(\"____ imputing the points ____\")\n",
        "  #creating UD function\n",
        "  ud_func= udf(reverseGeoCoder, StringType())\n",
        "  boro_cleaned_dataframe = boro_cleaner.withColumn(Boro, ud_func(boro_cleaner[lat_index], boro_cleaner[long_index]))\n",
        "\n",
        "  #joining the imputed dataset to the maindataset and returning\n",
        "  joiner_dataset=df_spark.filter((df_spark[Latitude].isNotNull()) & (df_spark[Longitude].isNotNull()) & (df_spark[Boro].isNotNull()))\n",
        "  fin_df=joiner_dataset.union(boro_cleaned_dataframe)\n",
        "  return fin_df"
      ],
      "metadata": {
        "id": "SZ6YnuUSz1vN"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ASSIGNMENT-3: SCALED PREPROCESSING\n",
        "\n",
        "Lets apply all the above functions to the different datasets"
      ],
      "metadata": {
        "id": "iymh68j97B8s"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXpbUgfWF1YT"
      },
      "source": [
        "## Shooting incidents dataset\n",
        "#columns to concentrate: \n",
        "#1. BORO_NM\n",
        "#2. PRECINCT\n",
        "#3. OCCUR_DATE\n",
        "#4. OCCUR_TIME\n",
        "#5. JURISDICTION_CODE\n",
        "#6. Latitude\n",
        "#7. Longitude\n",
        "#8. VIC_RACE\n",
        "#9. VIC_SEX\n",
        "#10. VIC_AGE_GROUP\n",
        "#11. PERP_AGE\n",
        "#12. PERP_SEX\n",
        "#13. PERP_RACE"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Service Call dataset\n",
        "#columns to concentrate: \n",
        "#1. BORO_NM\n",
        "#2. PATROL_BORO_NM\n",
        "#3. NYPD_PCT_CD\n",
        "#4. Latitude\n",
        "#5. Longitude\n",
        "#6. ARRIVD_TS\n",
        "#7. INCIDENT_DATE\n",
        "#8. INCIDENT_TIME"
      ],
      "metadata": {
        "id": "TpMra2llMx6k"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##NYPD Criminal Court Summons dataset\n",
        "#columns to concentrate: \n",
        "#1. SEX\n",
        "#2. RACE\n",
        "#3. PRECINCT_OF_OCCUR\n",
        "#4. Latitude\n",
        "#5. Longitude\n",
        "#6. SUMMONS_DATE\n",
        "#7. BORO\n",
        "#8. AGE_GROUP"
      ],
      "metadata": {
        "id": "1YlHQlCFS1pt"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##NYPD B Summons (Historic) dataset\n",
        "#columns to concentrate: \n",
        "#1. CITY_NM\n",
        "#2. VIOLATION_DATE\n",
        "#3. VIOLATION_TIME\n",
        "#4. Latitude\n",
        "#5. Longitude"
      ],
      "metadata": {
        "id": "tsYPcw9tgE4-"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Import dataset. Download it and store it in your drive\n",
        "\n",
        "\n",
        "Links for dataset to replace at \"fn_dst\" variable:\n",
        "\n",
        "1.   NYPD Shooting Incidents dataset: https://data.cityofnewyork.us/api/views/833y-fsy8/rows.csv?accessType=DOWNLOAD\n",
        "\n",
        "\n",
        "2.   List item\n",
        "\n"
      ],
      "metadata": {
        "id": "K21CeH2ViCRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. NYPD SHOOTING INCIDENTS DATASET:\n",
        "\n",
        "a. To get the required columns, use this module: \n",
        "\n",
        "\n",
        "1.   get_area_of_interest(df_spark, interested_columns)\n",
        "\n",
        "\n",
        "b. Preprocessing pipeline: Pass your data through these functions. (if your columns fall in those categories)\n",
        "\n",
        "1.   valid_date_check(date)\n",
        "2.   valid_time_check(time)\n",
        "3.   reverse_geo_code_boros(df_spark, Latitude, Longitude, Boro, lat_index, long_index)\n",
        "4.   refine_age_group_race(df_spark, victim_age_group=None, suspect_age_group=None, suspect_race=None, victim_race=None)\n",
        "5.   refine_sex_gender_impute(df_spark, suspect_age=None, suspect_gender=None, victim_age=None, victim_gender=None)\n",
        "6.   refine_precinct_jur(df_spark, precinct=None, Jur_code=None)\n",
        "\n"
      ],
      "metadata": {
        "id": "pex6Q3UumZWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Downloading file from NYC Open Data\n",
        "\n",
        "fn_src = 'https://data.cityofnewyork.us/api/views/833y-fsy8/rows.csv?accessType=DOWNLOAD'\n",
        "fn_dst = '/content/drive/MyDrive/NYPD_Shooting_Incident_Data__Historic_.csv'\n",
        "\n",
        "from six.moves import urllib\n",
        "\n",
        "if os.path.isfile(fn_dst):\n",
        "    print('File %s has already been downloaded' % fn_dst)\n",
        "else:\n",
        "    print('Fetching file %s[2.4GB]. This may take a while...' % fn_dst)\n",
        "    urllib.request.urlretrieve(fn_src, fn_dst)\n",
        "    print('File %s has been downloaded' % fn_dst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncyzk2o4hksz",
        "outputId": "70676c21-fb9d-433c-e59d-0a9780b50df5"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File /content/drive/MyDrive/NYPD_Shooting_Incident_Data__Historic_.csv has already been downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark=spark.read.option(\"header\",True).csv(fn_dst,inferSchema=True)"
      ],
      "metadata": {
        "id": "6dVXI110s5BO"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The size of dataset ~ 24k tuples. So, we need around 2000 data points for 95% confidence level with 2% interval. The size of data is almost 10% of the data. So we can get it into our df now"
      ],
      "metadata": {
        "id": "yuNanx2ntTwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark=df_spark.sample(0.1)"
      ],
      "metadata": {
        "id": "eyI-7lk0suZi"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU6bV3c-t3uk",
        "outputId": "513918dc-1329-4a5a-81eb-c212470b6de0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2375"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a. Select the columns that are common with the original dataset:\n",
        "1. BORO\n",
        "2. PRECINCT\n",
        "3. JURISDICTION_CODE\n",
        "4. PREP_AGE_GROUP\n",
        "5. PERP_RACE\n",
        "6. VIC_AGE_GROUP\n",
        "7. VIC_SEX\n",
        "8. Latitude\n",
        "9. Longitude\n",
        "10. VIC_RACE\n",
        "11. PERP_SEX\n",
        "12. OCCUR_DATE\n",
        "13. OCCUR_TIME\n",
        "\n",
        "We can consider the primary key along with this\n",
        "14. INCIDENT_KEY"
      ],
      "metadata": {
        "id": "4Vv8BJSmklby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interested_columns_1=['INCIDENT_KEY', 'OCCUR_TIME', 'OCCUR_DATE', 'BORO', 'PRECINCT', 'JURISDICTION_CODE', 'PERP_AGE_GROUP', 'PERP_RACE', 'PERP_SEX', 'VIC_AGE_GROUP', 'VIC_SEX', 'VIC_RACE', 'Latitude', 'Longitude']"
      ],
      "metadata": {
        "id": "-uxqvgVhjyE1"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark=get_area_of_interest(df_spark, interested_columns_1)"
      ],
      "metadata": {
        "id": "YkJ-dmj3vWOC"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b. Lets pass the dataset through the preprocessing pipeline"
      ],
      "metadata": {
        "id": "w8jEQpQhvibA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp=df_spark.rdd"
      ],
      "metadata": {
        "id": "GxVSX8aSwmJO"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Date and Time"
      ],
      "metadata": {
        "id": "jYlq5Tz8wSDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp_=df_temp.map(lambda x:(x, valid_date_check(x[2]))).filter(lambda x: x[1]==True)\n",
        "df_temp=df_temp_.map(lambda x: x[0])"
      ],
      "metadata": {
        "id": "UWc6qVTVvh-C"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp_=df_temp.map(lambda x:(x, valid_time_check(x[1]))).filter(lambda x: x[1]==True)\n",
        "df_temp=df_temp_.map(lambda x: x[0])"
      ],
      "metadata": {
        "id": "Ng9UyxmRvcga"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Age group, Race, Gender imputation"
      ],
      "metadata": {
        "id": "wCaYo8U6w7dS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #as this code requires the pyspark dataframe(Not the rdd)\n",
        "df_temp=df_temp.toDF(schema=df_spark.schema)"
      ],
      "metadata": {
        "id": "cGCBnkZwxe7I"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp=refine_age_group_race(df_temp, 'VIC_AGE_GROUP', 'PERP_AGE_GROUP', 'PERP_RACE', 'VIC_RACE')"
      ],
      "metadata": {
        "id": "yBzJ2X05vXTq"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp=refine_sex_gender_impute(df_temp, None, \"PERP_SEX\", None, \"VIC_SEX\")"
      ],
      "metadata": {
        "id": "apx2W4wNxVT6"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Geocoding"
      ],
      "metadata": {
        "id": "CpfygTLZzroP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_spk=reverse_geo_code_boros(df_temp, 'Latitude', 'Longitude', 'BORO', -2, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH37_eFZzUbm",
        "outputId": "4b8da3a6-095b-4055-bb1a-78fea982faff"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 0 points to impute\n",
            "___intializing Zip Code Look up ____\n",
            "____ imputing the points ____\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Precinct and Jurisdiction Code imputation\n"
      ],
      "metadata": {
        "id": "-WQs_teu7ZPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp=df_spk.rdd\n",
        "df_temp_=df_temp.map(lambda x:(x, valid_precinct_check(x[4]))).filter(lambda x: x[1]==True)\n",
        "df_temp=df_temp_.map(lambda x: x[0])\n",
        "\n",
        "df_temp_=df_temp.map(lambda x:(x, valid_jur_check(x[5]))).filter(lambda x: x[1]==True)\n",
        "df_temp=df_temp_.map(lambda x: x[0])\n",
        "\n",
        "df_spark=df_temp.toDF(schema=df_spark.schema)"
      ],
      "metadata": {
        "id": "jy5H5E7a-vxB"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbHNyCDB9xzz",
        "outputId": "dc09abc0-d5cc-453d-add1-3fde5d2d39e3"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(INCIDENT_KEY=137564752, OCCUR_TIME='00:25:00', OCCUR_DATE='07/04/2014', BORO='QUEENS', PRECINCT=101, JURISDICTION_CODE=0, PERP_AGE_GROUP='UNKNOWN', PERP_RACE='UNKNOWN', PERP_SEX='UNKNOWN', VIC_AGE_GROUP='18-24', VIC_SEX='M', VIC_RACE='BLACK', Latitude=40.59403780700006, Longitude=-73.75777869199999),\n",
              " Row(INCIDENT_KEY=73911288, OCCUR_TIME='01:34:00', OCCUR_DATE='07/29/2010', BORO='BROOKLYN', PRECINCT=77, JURISDICTION_CODE=2, PERP_AGE_GROUP='UNKNOWN', PERP_RACE='UNKNOWN', PERP_SEX='UNKNOWN', VIC_AGE_GROUP='25-44', VIC_SEX='M', VIC_RACE='BLACK', Latitude=40.67125355700006, Longitude=-73.92671475399999),\n",
              " Row(INCIDENT_KEY=149455199, OCCUR_TIME='00:08:00', OCCUR_DATE='01/17/2016', BORO='BROOKLYN', PRECINCT=72, JURISDICTION_CODE=0, PERP_AGE_GROUP='18-24', PERP_RACE='BLACK HISPANIC', PERP_SEX='M', VIC_AGE_GROUP='25-44', VIC_SEX='M', VIC_RACE='BLACK HISPANIC', Latitude=40.64819320200007, Longitude=-74.00711572799997),\n",
              " Row(INCIDENT_KEY=197700945, OCCUR_TIME='04:15:00', OCCUR_DATE='05/28/2019', BORO='BROOKLYN', PRECINCT=75, JURISDICTION_CODE=0, PERP_AGE_GROUP='UNKNOWN', PERP_RACE='UNKNOWN', PERP_SEX='UNKNOWN', VIC_AGE_GROUP='25-44', VIC_SEX='M', VIC_RACE='BLACK', Latitude=40.663161857000034, Longitude=-73.87983318099998),\n",
              " Row(INCIDENT_KEY=184699355, OCCUR_TIME='00:13:00', OCCUR_DATE='07/03/2018', BORO='BROOKLYN', PRECINCT=73, JURISDICTION_CODE=2, PERP_AGE_GROUP='UNKNOWN', PERP_RACE='UNKNOWN', PERP_SEX='UNKNOWN', VIC_AGE_GROUP='18-24', VIC_SEX='F', VIC_RACE='BLACK', Latitude=40.666744702000074, Longitude=-73.90616730899995),\n",
              " Row(INCIDENT_KEY=66112200, OCCUR_TIME='19:59:00', OCCUR_DATE='09/24/2009', BORO='BROOKLYN', PRECINCT=69, JURISDICTION_CODE=0, PERP_AGE_GROUP='UNKNOWN', PERP_RACE='BLACK', PERP_SEX='M', VIC_AGE_GROUP='18-24', VIC_SEX='M', VIC_RACE='BLACK', Latitude=40.63495663000003, Longitude=-73.89672118599998),\n",
              " Row(INCIDENT_KEY=161486738, OCCUR_TIME='22:45:00', OCCUR_DATE='01/31/2017', BORO='QUEENS', PRECINCT=102, JURISDICTION_CODE=0, PERP_AGE_GROUP='25-44', PERP_RACE='BLACK', PERP_SEX='M', VIC_AGE_GROUP='25-44', VIC_SEX='M', VIC_RACE='BLACK', Latitude=40.69185257300006, Longitude=-73.85350398299994),\n",
              " Row(INCIDENT_KEY=169761300, OCCUR_TIME='17:56:00', OCCUR_DATE='09/26/2017', BORO='BRONX', PRECINCT=50, JURISDICTION_CODE=0, PERP_AGE_GROUP='18-24', PERP_RACE='BLACK', PERP_SEX='M', VIC_AGE_GROUP='25-44', VIC_SEX='M', VIC_RACE='WHITE HISPANIC', Latitude=40.87111655600006, Longitude=-73.89851887099996),\n",
              " Row(INCIDENT_KEY=86096654, OCCUR_TIME='05:05:00', OCCUR_DATE='08/05/2012', BORO='QUEENS', PRECINCT=100, JURISDICTION_CODE=0, PERP_AGE_GROUP='UNKNOWN', PERP_RACE='UNKNOWN', PERP_SEX='UNKNOWN', VIC_AGE_GROUP='18-24', VIC_SEX='M', VIC_RACE='BLACK', Latitude=40.59268353900006, Longitude=-73.79908101899997),\n",
              " Row(INCIDENT_KEY=151747520, OCCUR_TIME='17:22:00', OCCUR_DATE='04/01/2016', BORO='BROOKLYN', PRECINCT=84, JURISDICTION_CODE=2, PERP_AGE_GROUP='<18', PERP_RACE='BLACK', PERP_SEX='M', VIC_AGE_GROUP='<18', VIC_SEX='M', VIC_RACE='BLACK', Latitude=40.69969442300004, Longitude=-73.98169269699997)]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets profile the data now."
      ],
      "metadata": {
        "id": "zA1yT-EQ8T3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pandasDF = df_spark.toPandas()\n",
        "ds=stream(pandasDF)\n",
        "\n",
        "#Creating profile of our dataset\n",
        "profiles = ds.profile(default_profiler=DefaultColumnProfiler)\n",
        "profiles.stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "XlCureog8pn7",
        "outputId": "d121beb0-71bd-40a9-aee2-b212adb7fb55"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total</th>\n",
              "      <th>empty</th>\n",
              "      <th>distinct</th>\n",
              "      <th>uniqueness</th>\n",
              "      <th>entropy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>INCIDENT_KEY</th>\n",
              "      <td>2375</td>\n",
              "      <td>0</td>\n",
              "      <td>2301</td>\n",
              "      <td>0.968842</td>\n",
              "      <td>11.150125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OCCUR_TIME</th>\n",
              "      <td>2375</td>\n",
              "      <td>0</td>\n",
              "      <td>925</td>\n",
              "      <td>0.389474</td>\n",
              "      <td>9.453297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OCCUR_DATE</th>\n",
              "      <td>2375</td>\n",
              "      <td>0</td>\n",
              "      <td>1814</td>\n",
              "      <td>0.763789</td>\n",
              "      <td>10.699901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BORO</th>\n",
              "      <td>2375</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.002105</td>\n",
              "      <td>1.964757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRECINCT</th>\n",
              "      <td>2375</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>0.030316</td>\n",
              "      <td>5.540832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>JURISDICTION_CODE</th>\n",
              "      <td>2375</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.001263</td>\n",
              "      <td>0.687710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PERP_AGE_GROUP</th>\n",
              "      <td>2375</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.002947</td>\n",
              "      <td>1.821710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PERP_RACE</th>\n",
              "      <td>2375</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0.002526</td>\n",
              "      <td>1.651526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PERP_SEX</th>\n",
              "      <td>2375</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.001684</td>\n",
              "      <td>1.331222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VIC_AGE_GROUP</th>\n",
              "      <td>2375</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0.002526</td>\n",
              "      <td>1.738510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VIC_SEX</th>\n",
              "      <td>2375</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000842</td>\n",
              "      <td>0.450714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VIC_RACE</th>\n",
              "      <td>2375</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0.002526</td>\n",
              "      <td>1.284115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Latitude</th>\n",
              "      <td>2375</td>\n",
              "      <td>0</td>\n",
              "      <td>1953</td>\n",
              "      <td>0.822316</td>\n",
              "      <td>10.803995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Longitude</th>\n",
              "      <td>2375</td>\n",
              "      <td>0</td>\n",
              "      <td>1953</td>\n",
              "      <td>0.822316</td>\n",
              "      <td>10.803995</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   total  empty  distinct  uniqueness    entropy\n",
              "INCIDENT_KEY        2375      0      2301    0.968842  11.150125\n",
              "OCCUR_TIME          2375      0       925    0.389474   9.453297\n",
              "OCCUR_DATE          2375      0      1814    0.763789  10.699901\n",
              "BORO                2375      0         5    0.002105   1.964757\n",
              "PRECINCT            2375      0        72    0.030316   5.540832\n",
              "JURISDICTION_CODE   2375      0         3    0.001263   0.687710\n",
              "PERP_AGE_GROUP      2375      0         7    0.002947   1.821710\n",
              "PERP_RACE           2375      0         6    0.002526   1.651526\n",
              "PERP_SEX            2375      0         4    0.001684   1.331222\n",
              "VIC_AGE_GROUP       2375      0         6    0.002526   1.738510\n",
              "VIC_SEX             2375      0         2    0.000842   0.450714\n",
              "VIC_RACE            2375      0         6    0.002526   1.284115\n",
              "Latitude            2375      0      1953    0.822316  10.803995\n",
              "Longitude           2375      0      1953    0.822316  10.803995"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. NYPD B Summons (Historic) dataset\n",
        "\n",
        "a. To get the required columns, use this module: \n",
        "\n",
        "\n",
        "1.   get_area_of_interest(df_spark, interested_columns)\n",
        "\n",
        "\n",
        "b. Preprocessing pipeline: Pass your data through these functions. (if your columns fall in those categories)\n",
        "\n",
        "1.   valid_date_check(date)\n",
        "2.   valid_time_check(time)\n",
        "3.   reverse_geo_code_boros(df_spark, Latitude, Longitude, Boro, lat_index, long_index)\n",
        "4.   refine_age_group_race(df_spark, victim_age_group=None, suspect_age_group=None, suspect_race=None, victim_race=None)\n",
        "5.   refine_sex_gender_impute(df_spark, suspect_age=None, suspect_gender=None, victim_age=None, victim_gender=None)\n",
        "6.   refine_precinct_jur(df_spark, precinct=None, Jur_code=None)\n",
        "\n"
      ],
      "metadata": {
        "id": "_RDjUMyBAd7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jg0TDO-sAQ-a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}